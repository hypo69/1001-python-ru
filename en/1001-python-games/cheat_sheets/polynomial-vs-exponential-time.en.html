<h3><strong>Polynomial Time</strong></h3>
<p><strong>Polynomial time</strong> is a term used in computational complexity theory to describe the running time of an algorithm that grows as a polynomial of the input size. If the running time of an algorithm can be expressed as \(O(n^k)\), where \(n\) is the input size and \(k\) is a constant, then such an algorithm runs in polynomial time.</p>
<h4><strong>Examples:</strong></h4>
<ol>
<li><strong>List sorting</strong>: Algorithms such as merge sort or quicksort run in \(O(n \log n)\), which is polynomial time.</li>
<li><strong>Shortest path in a graph</strong>: Dijkstra's algorithm runs in \(O(n^2)\) or \(O(n \log n)\) depending on the implementation, which is also polynomial.</li>
</ol>
<h4><strong>Features:</strong></h4>
<ul>
<li>Algorithms that run in polynomial time are considered <strong>efficient</strong> and <strong>practically applicable</strong>.</li>
<li>Problems that can be solved in polynomial time belong to class <strong>P</strong>.</li>
</ul>
<hr>
<h3><strong>Exponential Time</strong></h3>
<p><strong>Exponential time</strong> is the running time of an algorithm that grows exponentially with the input size. If the running time can be expressed as \(O(k^n)\), where \(n\) is the input size and \(k\) is a constant, then such an algorithm runs in exponential time.</p>
<h4><strong>Examples:</strong></h4>
<ol>
<li><strong>Traveling salesman problem</strong>: Solving by brute-force enumeration of all possible routes requires \(O(n!)\) time, which is worse than exponential.</li>
<li><strong>Enumerating all subsets</strong>: An algorithm that checks all possible subsets of a set of \(n\) elements runs in \(O(2^n)\).</li>
</ol>
<h4><strong>Features:</strong></h4>
<ul>
<li>Algorithms that run in exponential time are considered <strong>inefficient</strong> for large inputs, as the running time becomes impractically large even for relatively small \(n\).</li>
<li>Problems that can only be solved in exponential time often belong to <strong>NP-hard</strong> or <strong>NP-complete</strong> classes.</li>
</ul>
<hr>
<h3><strong>Comparison of Polynomial and Exponential Time</strong></h3>
<table>
<thead>
<tr>
<th><strong>Characteristic</strong></th>
<th><strong>Polynomial Time</strong></th>
<th><strong>Exponential Time</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Growth of running time</strong></td>
<td>Slow (e.g., \(n^2\), \(n^3\))</td>
<td>Fast (e.g., \(2^n\), \(3^n\))</td>
</tr>
<tr>
<td><strong>Examples of problems</strong></td>
<td>Sorting, shortest path</td>
<td>Traveling salesman problem, subset enumeration</td>
</tr>
<tr>
<td><strong>Practical applicability</strong></td>
<td>Efficient for large data</td>
<td>Impractical for large data</td>
</tr>
<tr>
<td><strong>Complexity class</strong></td>
<td>P</td>
<td>NP-hard, NP-complete</td>
</tr>
</tbody>
</table>
<hr>
<h3><strong>Why is this important?</strong></h3>
<ol>
<li><strong>Polynomial time</strong>:
<ul>
<li>Algorithms that run in polynomial time are considered <strong>practically applicable</strong>, as they can process large amounts of data in a reasonable time.</li>
<li>Problems of class <strong>P</strong> (solvable in polynomial time) are the basis for many applications in computer science, such as data processing, networks, cryptography, and artificial intelligence.</li>
</ul>
</li>
<li><strong>Exponential time</strong>:
<ul>
<li>Algorithms that run in exponential time become <strong>impractical</strong> even for relatively small inputs. For example, for \(n = 100\), \(2^n\) already exceeds the number of atoms in the observable Universe.</li>
<li>Problems that can only be solved in exponential time often require the use of <strong>approximate methods</strong>, <strong>heuristics</strong>, or <strong>parallel computing</strong>.</li>
</ul>
</li>
</ol>
<hr>
<h3><strong>Example for understanding</strong></h3>
<p>Imagine you have a problem, and you want to solve it for \(n = 10\) and \(n = 100\):</p>
<ul>
<li><strong>Polynomial time (\(n^2\))</strong>:
<ul>
<li>For \(n = 10\): \(10^2 = 100\) operations.</li>
<li>For \(n = 100\): \(100^2 = 10\,000\) operations.</li>
</ul>
</li>
<li><strong>Exponential time (\(2^n\))</strong>:
<ul>
<li>For \(n = 10\): \(2^{10} = 1\,024\) operations.</li>
<li>For \(n = 100\): \(2^{100} \approx 1.26 \times 10^{30}\) operations.</li>
</ul>
</li>
</ul>
<p>As you can see, for \(n = 100\) a polynomial algorithm will perform 10,000 operations, which is quite feasible, while an exponential algorithm will require \(1.26 \times 10^{30}\) operations, which is practically impossible.</p>
<p>To plot graphs illustrating the difference between polynomial and exponential time, various mathematical functions can be used. Here are examples of functions that can be used for visualization:</p>
<hr>
<h3><strong>Polynomial functions</strong></h3>
<ol>
<li><strong>Linear function</strong>: <br>
   \( f(n) = n \) <br>
   Example: running time of an algorithm that processes each element once.</li>
<li><strong>Quadratic function</strong>: <br>
   \( f(n) = n^2 \) <br>
   Example: running time of an algorithm with nested loops, such as bubble sort.</li>
<li><strong>Cubic function</strong>: <br>
   \( f(n) = n^3 \) <br>
   Example: running time of an algorithm that processes three-dimensional data.</li>
<li><strong>Logarithmic function</strong>: <br>
   \( f(n) = \log n \) <br>
   Example: running time of binary search.</li>
<li><strong>Linearithmic function</strong>: <br>
   \( f(n) = n \log n \) <br>
   Example: running time of quicksort or merge sort.</li>
</ol>
<hr>
<h3><strong>Exponential functions</strong></h3>
<ol>
<li><strong>Exponential function</strong>: <br>
   \( f(n) = 2^n \) <br>
   Example: running time of an algorithm that enumerates all subsets of a set.</li>
<li><strong>Factorial function</strong>: <br>
   \( f(n) = n! \) <br>
   Example: running time of an algorithm that enumerates all permutations (e.g., traveling salesman problem).</li>
<li><strong>Exponential function with a different base</strong>: <br>
   \( f(n) = 3^n \) <br>
   Example: running time of an algorithm that explores all possible combinations.</li>
</ol>
<hr>
<h3><strong>Code example for plotting (Python, Matplotlib)</strong></h3>
<pre class="line-numbers"><code class="language-python">import matplotlib.pyplot as plt
import numpy as np

# Range of n values
n = np.linspace(1, 20, 100)

# Polynomial functions
linear = n
quadratic = n**2
cubic = n**3
logarithmic = np.log(n)
nlogn = n * np.log(n)

# Exponential functions
exponential = 2**n
factorial = [np.math.factorial(int(i)) for i in n]  # Factorial is defined only for integers

# Plotting
plt.figure(figsize=(10, 6))

# Polynomial functions
plt.plot(n, linear, label='Linear: $f(n) = n$')
plt.plot(n, quadratic, label='Quadratic: $f(n) = n^2$')
plt.plot(n, cubic, label='Cubic: $f(n) = n^3$')
plt.plot(n, logarithmic, label='Logarithmic: $f(n) = \log n$')
plt.plot(n, nlogn, label='Linearithmic: $f(n) = n \log n$')

# Exponential functions
plt.plot(n, exponential, label='Exponential: $f(n) = 2^n$')
plt.plot(n, factorial, label='Factorial: $f(n) = n!$')

# Plot settings
plt.yscale('log')  # Logarithmic scale for convenience
plt.xlabel('Input size (n)')
plt.ylabel('Time complexity')
plt.title('Comparison of Polynomial and Exponential Time Complexity')
plt.legend()
plt.grid(True)
plt.show()
</code></pre>
<hr>
<h3><strong>What will the graph show?</strong></h3>
<ul>
<li><strong>Polynomial functions</strong> grow slowly and remain at the bottom of the graph.</li>
<li><strong>Exponential functions</strong> grow very quickly and shoot up even with small values of \(n\).</li>
<li>Using a <strong>logarithmic scale</strong> (on the Y-axis) helps visualize the difference between polynomial and exponential functions, as their values differ by orders of magnitude.</li>
</ul>
