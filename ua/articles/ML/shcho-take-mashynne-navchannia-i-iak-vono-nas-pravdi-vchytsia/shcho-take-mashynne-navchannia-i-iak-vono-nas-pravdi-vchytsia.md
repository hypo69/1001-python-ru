# Що таке машинне навчання — і як воно насправді «вчится»?
![1](../assets/Что_такое_машинное_обучение_и_как_оно_на_самом_деле_учится/1.png)

*Чотири коти, на яких тримається машинне навчання*

Чим машинне навчання відрізняється від традиційного програмування з його «працює, доки не чіпаєш»? Де закінчуються чіткі алгоритми — і де починається магія «чорної скриньки», як у випадку з ChatGPT?

*Це перша стаття в науково-популярній серії, де ми розберемо основи ШІ — без порожніх слів, без кліше, без академічного туману і, в ідеалі, без рівнянь (як одного разу написав Стівен Хокінг: кожна формула в науково-популярній книзі скорочує її продажі вдвічі).*

Сьогодні ми поговоримо про саму основу: які типи навчання використовують моделі ШІ, навіщо вони взагалі потрібні і як вони визначають, на що здатна модель.

Так, будуть котики. І трохи сарказму. Але виключно в благородних цілях — для створення сильних і запам'ятовуваних асоціацій.

Ця стаття для всіх, хто починає знайомитися з ШІ: для технічних та нетехнічних читачів, архітекторів рішень, засновників стартапів, досвідчених розробників та всіх, хто хоче нарешті скласти чітке уявлення про те, що таке машинне навчання і з чого все починається.

У цій частині ми розглянемо основи:
Що таке МО, чим воно кардинально відрізняється від традиційного програмування, і чотири ключові парадигми навчання, які лежать в основі всього сучасного ландшафту ШІ.

#### Класичне програмування проти машинного навчання

Якщо ви вже впевнені у своєму розумінні того, чим машинне навчання відрізняється від традиційного програмування, сміливо пропускайте цей розділ. Але якщо ви хочете прояснити цю відмінність — це може допомогти.

Почнемо з простої аналогії.

Калькулятор виконує одну арифметичну операцію за раз — і тільки за прямою командою. Комп'ютер з традиційним кодом йде на крок далі: він виконує заздалегідь визначені програми, приймає рішення за допомогою керуючих структур, зберігає проміжні значення та обробляє кілька входів. Це чудово працює, коли вхідні дані передбачувані, а поведінку можна описати жорсткою, детермінованою логікою.

Але цей підхід дає збій у заплутаних, неоднозначних або невизначених ситуаціях.

Наприклад, спробуйте написати повний набір правил `if/else`, щоб:
*   відрізнити Місяць від круглого стельового світильника,
*   розібрати недбалий почерк,
*   або виявити сарказм у твіті.

Це не масштабується. Ви швидко стикаєтеся з комбінаторним вибухом окремих випадків

Саме тут класичне програмування впирається у свою стелю, і починається машинне навчання.

Можна думати про МО як про наступний рівень абстракції: якщо калькулятори працюють з арифметикою, а код — зі структурованою логікою, то МО справляється з неструктурованою невизначеністю. Навіть нечітка логіка — з її градієнтами та порогами — часто не справляється зі складністю реального світу. МО взагалі не покладається на заздалегідь написані правила; замість цього воно навчається поведінці на основі даних.

Замість того, щоб говорити машині, *що робити*, ви показуєте їй, *що хочете отримати*, і вона статистично з'ясовує, *як* це зробити. Навчання відбувається не через жорстко закодовані інструкції, а через патерни, ймовірності та узагальнення.
![2](../assets/Что_такое_машинное_обучение_и_как_оно_на_самом_деле_учится/2.png)

*Розпізнавання рукописного тексту та зображень — це лише два приклади завдань, де неможливо передбачити всі сценарії.*

Залежно від свого навчання, модель МО може побачити букву, яку ніколи раніше не зустрічала, і все одно розпізнати її — ґрунтуючись на тисячах схожих зразків рукописного тексту. Вона може визначити, що користувач намалював динозавра, навіть якщо саме такого силуету не було в навчальних даних, — тому що вона розуміє форми, пропорції та текстуру не як правила, а як розподіли. Замість того, щоб жорстко слідувати заздалегідь написаному сценарію, — вона вгадує.

#### Парадигми машинного навчання

Те, що може робити модель ШІ, сильно залежить від того, як її навчали.

Насамперед, моделі ШІ класифікуються за їхніми парадигмами навчання. Парадигма визначає сильні та слабкі сторони моделі.

Більшість методів машинного навчання належать до однієї з чотирьох основних парадигм:
*   Навчання з учителем
*   Навчання без учителя
*   Навчання з підкріпленням
*   Самостійне навчання (іноді також називається «самонавчанням»)

#### Навчання з учителем (Supervised Learning)
![3](../assets/Что_такое_машинное_обучение_и_как_оно_на_самом_деле_учится/3.png)

Як навчити модель відрізняти котів від собак на фотографіях? Ви показуєте їй десятки тисяч зображень — кожне з правильною міткою: «Це кішка» або «Це собака». Модель починає шукати закономірності: «Ага, у котів є трикутні вуха, а у собак — довгі морди». Вона не знає, що таке кішка чи собака, але вона бачить, що деякі зображення схожі одне на одне, а інші — ні. І з кожним новим прикладом вона стає все кращою в розпізнаванні цих патернів. Після тисяч ітерацій модель починає помічати дещо сама: у котів трикутні вуха, підозрілий погляд і схильність ґрунтовно вмощуватися на клавіатуру. Це і є навчання з учителем — тренування на розмічених прикладах, де «правильна» відповідь відома заздалегідь.

По суті, ви говорите: «Ось вхідні дані — а ось очікуваний результат». Завдання моделі — виявити закономірності та узагальнити їх на нові, небачені дані.

![4](../assets/Что_такое_машинное_обучение_и_как_оно_на_самом_деле_учится/4.png)

*Після тисячі фотографій котів модель вловила суть: трикутні вуха — це важливо. Тепер вона використовує це, щоб відрізняти котів від собак*

**Типові приклади використання:**
*   **Класифікація** (наприклад, спам проти не спаму)
*   **Регресія** (наприклад, прогнозування ціни)
*   **Оцінка ймовірності** (наприклад, ймовірність відтоку клієнтів)

**Навчання з учителем у реальному світі:**
*   **Аналіз тональності:** *Вхід:* текст відгуку → *Вихід:* позитивний / негативний
*   **Фільтрація спаму:** *Вхід:* текст листа → *Вихід:* спам / не спам
*   **Медична діагностика:** *Вхід:* результати аналізів → *Вихід:* здоровий / хворий
*   **Модерація контенту:** *Вхід:* текст або зображення → *Вихід:* допустимо / порушує правила
*   **Категоризація товарів:** *Вхід:* опис товару → *Вихід:* категорія каталогу
*   **OCR (Оптичне розпізнавання):** *Вхід:* фото документа → *Вихід:* витягнутий текст

#### Навчання без учителя (Unsupervised Learning)
![5](../assets/Что_такое_машинное_обучение_и_как_оно_на_самом_деле_учится/5.png)

*Іноді здається, що динозаври — це просто самовпевнені жаби.*

У цій парадигмі модель навчається на нерозмічених даних, тобто їй ніколи не говорять, яка відповідь «правильна». Замість цього вона намагається самостійно виявити приховану структуру, закономірності або взаємозв'язки. Думайте про це як про спробу організувати хаос за категоріями, коли ніхто ніколи не говорив вам, якими ці категорії повинні бути.

Уявіть, що ви показуєте моделі тисячі зображень — котів, собак, жаб та динозаврів (припустимо, для ясності, що ми якимось чином отримали чіткі фотографії вимерлих рептилій). Але ми не говоримо моделі, хто є хто. Насправді, модель навіть не знає, скільки існує категорій: три? п'ять? п'ятдесят? Вона просто шукає візуальні закономірності. Зрештою, вона починає групувати пухнастих істот в один кластер, а тих, у кого гладка шкіра, очі з боків і зловісно холодний погляд, — в інший.

![6](../assets/Что_такое_машинное_обучение_и_как_оно_на_самом_деле_учится/6.png)

Після тисяч прикладів модель зрештою вирішує: «Складемо все пухнасте в коробку №1,
а все з блискучою шкірою та очима з боків — в коробку №2». Самі мітки не мають значення — важливо те,
що вміст кожної коробки стає все більш однорідним.

Моделі без учителя не намагаються передбачати мітки. Замість цього вони:
*   **Групують схожі об'єкти (кластеризація)**
*   **Виявляють викиди або аномалії**
*   **Знижують розмірність (спрощують складні дані)**

Ця парадигма особливо корисна, коли:
*   Розмітка даних занадто дорога або непрактична
*   Ви ще не знаєте, що шукаєте
*   Ви хочете виявити сегменти або поведінкові патерни без заздалегідь визначених категорій

#### Навчання з підкріпленням (Reinforcement Learning)

У цій парадигмі модель — звана агентом — навчається, взаємодіючи зі середовищем методом проб і помилок. Агент пробує різні дії та спостерігає за реакцією середовища. Дії, які наближають до бажаного результату, приносять нагороди; неефективні або шкідливі дії призводять до штрафів.

Спробуємо дресирувати кішку. (Так, ми знаємо, що в реальному житті це майже неможливо, але ми вже взялися за котячу тему, тож ось ми тут.)
Кішка — це агент. Квартира — це середовище. Кішка пробує різні дії: Зловила муху → отримала ласощі (нагорода) Скинула телевізор → залишилася без вечері (штраф)
Через багаторазовий досвід кішка починає поводитися корисним чином — не тому, що вона розуміє, чого ви хочете, а тому, що вона вивчила політику: набір дій, які найчастіше призводять до їжі. Їй не потрібні правила — вона навчається на наслідках.

![7](../assets/Что_такое_машинное_обучение_и_как_оно_на_самом_деле_учится/7.png)

*Як показує графік — криком нічого не доб'єшся.)*

**Навчання з підкріпленням використовується, коли:**
*   Поведінка повинна покращуватися з часом
*   Немає заздалегідь визначених «правильних» відповідей
*   Наслідки відкладені, а не миттєві

#### Самостійне навчання (Self-Supervised Learning)

У цьому підході модель навчається на нерозмічених даних, але завдання для навчання витягується з самих даних — без участі людини в розмітці. Модель навчається передбачати одну частину вхідних даних на основі іншої.

**Приклад**
Вихідне речення: *«Кіт застрибнув на клавіатуру і залив незакінчений код у продакшн».*

Ми можемо перетворити це на завдання для навчання. Наприклад:
*   **Замаскувати слово:** *вхід:* «Кіт застрибнув на \*\*\* і розгорнув незакінчений код...», *ціль:* передбачити слово **клавіатура**.
*   **Обірвати речення:** *вхід:* «Кіт застрибнув на...», *ціль:* продовжити речення.

![8](../assets/Что_такое_машинное_обучение_и_как_оно_на_самом_деле_учится/8.png)

*Для Тензорного Кота писати догори ногами — це всього лише питання вибору правильної системи координат.*

Ці пари «вхід + ціль» генеруються автоматично, без ручної розмітки. Та ж ідея застосовується до різних типів даних, таких як зображення (передбачення відсутніх фрагментів) або аудіо.

**Реальні застосування самостійного навчання:**
*   **Мовні моделі** (GPT, LLaMA, Claude)
*   **Комп'ютерний зір** (CLIP, DINO)
*   **Аудіо та мова** (Wav2Vec 2.0)
*   **Мультимодальні моделі** (Gemini, CLIP)
*   **Попереднє навчання (фундаментальні моделі)**

**Основна ідея**
Модель навчається на автоматично згенерованих завданнях, де «правильна відповідь» витягується безпосередньо з самих даних. Це дає нам масштабованість, здатність до узагальнення та основу для більшості сучасних генеративних та мовних систем.

#### Зведення за парадигмами навчання

| Парадигма                 | Як навчається модель                                         |
|---------------------------|--------------------------------------------------------------|
| Навчання з учителем       | На розмічених даних (вхід → правильна відповідь)              |
| Навчання без учителя      | На нерозмічених даних (модель сама знаходить структуру)      |
| Навчання з підкріпленням  | Через взаємодію зі середовищем через нагороди та штрафи        |
| Самостійне навчання | На нерозмічених даних, де завдання генеруються з них же   |

#### Що ще існує?

Крім цих чотирьох, існують й інші підходи (частково-контрольоване, активне, онлайн-навчання тощо). Вони рідко розглядаються як самостійні парадигми, тому що зазвичай є гібридами або варіаціями основних стратегій, які ми вже розглянули. Для розуміння суті машинного навчання — достатньо освоїти ці чотири.

У наступній частині ми зануримося в те, що таке нейронна мережа насправді: нейрони, ваги, зв'язки. Як вона «вчится»? Навіщо їй взагалі потрібні шари? І яке відношення купа чисел має до розуміння мови, зображень чи... реальності?

Ми знімемо шар за шаром — і спробуємо відповісти на єдине питання, яке має значення:

**Тож чи є тут хоч якась магія... чи це просто замаскована математика?**

https://medium.com/@paul.ilvez/how-ai-learns-no-formulas-but-plenty-of-cats-fc43471add24
