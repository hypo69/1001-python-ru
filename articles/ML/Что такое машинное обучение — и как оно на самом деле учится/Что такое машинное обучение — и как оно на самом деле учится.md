# Что такое машинное обучение — и как оно на самом деле «учится»?
![1](../assets/Что_такое_машинное_обучение_и_как_оно_на_самом_деле_учится/1.png)

*Четыре кота, на которых держится машинное обучение*

Чем машинное обучение отличается от традиционного программирования с его «работает, пока не трогаешь»? Где заканчиваются четкие алгоритмы — и где начинается магия «черного ящика», как в случае с ChatGPT?

*Это первая статья в научно-популярной серии, где мы разберем основы ИИ — без пустых слов, без клише, без академического тумана и, в идеале, без уравнений (как однажды написал Стивен Хокинг: каждая формула в научно-популярной книге сокращает ее продажи вдвое).*

Сегодня мы поговорим о самом фундаменте: какие типы обучения используют модели ИИ, зачем они вообще нужны и как они определяют, на что способна модель.

Да, будут котики. И немного сарказма. Но исключительно в благородных целях — для создания сильных и запоминающихся ассоциаций.

Эта статья для всех, кто начинает знакомиться с ИИ: для технических и нетехнических читателей, архитекторов решений, основателей стартапов, опытных разработчиков и всех, кто хочет наконец-то составить ясное мысленное представление о том, что такое машинное обучение и с чего все начинается.

В этой части мы рассмотрим основы:
Что такое МО, чем оно кардинально отличается от традиционного программирования, и четыре ключевые парадигмы обучения, которые лежат в основе всего современного ландшафта ИИ.

#### Классическое программирование против машинного обучения

Если вы уже уверены в своем понимании того, чем машинное обучение отличается от традиционного программирования, смело пропускайте этот раздел. Но если вы хотите прояснить это различие — это может помочь.

Начнем с простой аналогии.

Калькулятор выполняет одну арифметическую операцию за раз — и только по прямой команде. Компьютер с традиционным кодом идет на шаг дальше: он выполняет заранее определенные программы, принимает решения с помощью управляющих структур, хранит промежуточные значения и обрабатывает несколько входов. Это отлично работает, когда входные данные предсказуемы, а поведение можно описать жесткой, детерминированной логикой.

Но этот подход дает сбой в запутанных, неоднозначных или неопределенных ситуациях.

Например, попробуйте написать полный набор правил `if/else`, чтобы:
*   отличить Луну от круглого потолочного светильника,
*   разобрать небрежный почерк,
*   или обнаружить сарказм в твите.

Это не масштабируется. Вы быстро сталкиваетесь с комбинаторным взрывом частных случаев

Именно здесь классическое программирование упирается в свой потолок, и начинается машинное обучение.

Можно думать о МО как о следующем уровне абстракции: если калькуляторы работают с арифметикой, а код — со структурированной логикой, то МО справляется с неструктурированной неопределенностью. Даже нечеткая логика — с ее градиентами и порогами — часто не справляется со сложностью реального мира. МО вообще не полагается на заранее написанные правила; вместо этого оно учится поведению на основе данных.

Вместо того чтобы говорить машине, *что делать*, вы показываете ей, *что хотите получить*, и она статистически выясняет, *как* это сделать. Обучение происходит не через жестко закодированные инструкции, а через паттерны, вероятности и обобщение.
![2](../assets/Что_такое_машинное_обучение_и_как_оно_на_самом_деле_учится/2.png)

*Распознавание рукописного текста и изображений — это лишь два примера задач, где невозможно предсказать все сценарии.*

В зависимости от своего обучения, модель МО может увидеть букву, которую никогда раньше не встречала, и все равно распознать ее — основываясь на тысячах похожих образцов рукописного текста. Она может определить, что пользователь нарисовал динозавра, даже если именно такого силуэта не было в обучающих данных, — потому что она понимает формы, пропорции и текстуру не как правила, а как распределения. Вместо того чтобы жестко следовать заранее написанному сценарию, — она угадывает.

#### Парадигмы машинного обучения

То, что может делать модель ИИ, сильно зависит от того, как ее обучали.

В первую очередь, модели ИИ классифицируются по их парадигмам обучения. Парадигма определяет сильные и слабые стороны модели.

Большинство методов машинного обучения относятся к одной из четырех основных парадигм:
*   Обучение с учителем
*   Обучение без учителя
*   Обучение с подкреплением
*   Самостоятельное обучение (иногда также называемое «самообучением»)

#### Обучение с учителем (Supervised Learning)
![3](../assets/Что_такое_машинное_обучение_и_как_оно_на_самом_деле_учится/3.png)

Как обучить модель отличать кошек от собак на фотографиях? Вы показываете ей десятки тысяч изображений — каждое с правильной меткой: «Это кошка» или «Это собака». Модель начинает искать закономерности: «Ага, у кошек есть треугольные уши, а у собак — длинные морды». Она не знает, что такое кошка или собака, но она видит, что некоторые изображения похожи друг на друга, а другие — нет. И с каждым новым примером она становится все лучше в распознавании этих паттернов. После тысяч итераций модель начинает замечать кое-что сама: у кошек треугольные уши, подозрительный взгляд и склонность основательно усаживаться на клавиатуру. Это и есть обучение с учителем — тренировка на размеченных примерах, где «правильный» ответ известен заранее.

По сути, вы говорите: «Вот входные данные — а вот ожидаемый результат». Задача модели — обнаружить закономерности и обобщить их на новые, невиданные данные.

![4](../assets/Что_такое_машинное_обучение_и_как_оно_на_самом_деле_учится/4.png)

*После тысячи фотографий кошек модель уловила суть: треугольные уши — это важно. Теперь она использует это, чтобы отличать кошек от собак*

**Типичные примеры использования:**
*   **Классификация** (например, спам vs. не спам)
*   **Регрессия** (например, прогнозирование цены)
*   **Оценка вероятности** (например, вероятность оттока клиентов)

**Обучение с учителем в реальном мире:**
*   **Анализ тональности:** *Вход:* текст отзыва → *Выход:* позитивный / негативный
*   **Фильтрация спама:** *Вход:* текст письма → *Выход:* спам / не спам
*   **Медицинская диагностика:** *Вход:* результаты анализов → *Выход:* здоров / болен
*   **Модерация контента:** *Вход:* текст или изображение → *Выход:* допустимо / нарушает правила
*   **Категоризация товаров:** *Вход:* описание товара → *Выход:* категория каталога
*   **OCR (Оптическое распознавание):** *Вход:* фото документа → *Выход:* извлеченный текст

#### Обучение без учителя (Unsupervised Learning)
![5](../assets/Что_такое_машинное_обучение_и_как_оно_на_самом_деле_учится/5.png)

*Иногда кажется, что динозавры — это просто самоуверенные лягушки.*

В этой парадигме модель обучается на неразмеченных данных, то есть ей никогда не говорят, какой ответ «правильный». Вместо этого она пытается самостоятельно обнаружить скрытую структуру, закономерности или взаимосвязи. Думайте об этом как о попытке организовать хаос по категориям, когда никто никогда не говорил вам, какими эти категории должны быть.

Представьте, что вы показываете модели тысячи изображений — кошек, собак, лягушек и динозавров (предположим, для ясности, что мы каким-то образом получили четкие фотографии вымерших рептилий). Но мы не говорим модели, кто есть кто. На самом деле, модель даже не знает, сколько существует категорий: три? пять? пятьдесят? Она просто ищет визуальные закономерности. В конце концов, она начинает группировать пушистых существ в один кластер, а тех, у кого гладкая кожа, глаза по бокам и зловеще холодный взгляд, — в другой.

![6](../assets/Что_такое_машинное_обучение_и_как_оно_на_самом_деле_учится/6.png)

После тысяч примеров модель в конечном итоге решает: «Сложим все пушистое в коробку №1, 
а все с блестящей кожей и глазами по бокам — в коробку №2». Сами метки не имеют значения — важно то, 
что содержимое каждой коробки становится все более однородным.

Модели без учителя не пытаются предсказывать метки. Вместо этого они:
*   **Группируют похожие объекты (кластеризация)**
*   **Обнаруживают выбросы или аномалии**
*   **Снижают размерность (упрощают сложные данные)**

Эта парадигма особенно полезна, когда:
*   Разметка данных слишком дорога или непрактична
*   Вы еще не знаете, что ищете
*   Вы хотите обнаружить сегменты или поведенческие паттерны без предопределенных категорий

#### Обучение с подкреплением (Reinforcement Learning)

В этой парадигме модель — называемая агентом — учится, взаимодействуя со средой методом проб и ошибок. Агент пробует разные действия и наблюдает за реакцией среды. Действия, которые приближают к желаемому результату, приносят награды; неэффективные или вредные действия приводят к штрафам.

Попробуем дрессировать кошку. (Да, мы знаем, что в реальной жизни это почти невозможно, но мы уже взялись за кошачью тему, так что вот мы здесь.)
Кошка — это агент. Квартира — это среда. Кошка пробует разные действия: Поймала муху → получила лакомство (награда) Скинула телевизор → осталась без ужина (штраф)
Через многократный опыт кошка начинает вести себя полезным образом — не потому, что она понимает, чего вы хотите, а потому, что она выучила политику: набор действий, которые чаще всего приводят к еде. Ей не нужны правила — она учится на последствиях.

![7](../assets/Что_такое_машинное_обучение_и_как_оно_на_самом_деле_учится/7.png)

*Как показывает график — криком ничего не добьешься.)*

**Обучение с подкреплением используется, когда:**
*   Поведение должно улучшаться со временем
*   Нет предопределенных «правильных» ответов
*   Последствия отложены, а не мгновенны

#### Самостоятельное обучение (Self-Supervised Learning)

В этом подходе модель обучается на неразмеченных данных, но задача для обучения извлекается из самих данных — без участия человека в разметке. Модель учится предсказывать одну часть входных данных на основе другой.

**Пример**
Исходное предложение: *«Кот запрыгнул на клавиатуру и залил незаконченный код в продакшн».*

Мы можем превратить это в задачу для обучения. Например:
*   **Замаскировать слово:** *вход:* «Кот запрыгнул на \*\*\* и развернул незаконченный код...», *цель:* предсказать слово **клавиатура**.
*   **Оборвать предложение:** *вход:* «Кот запрыгнул на...», *цель:* продолжить предложение.

![8](../assets/Что_такое_машинное_обучение_и_как_оно_на_самом_деле_учится/8.png)

*Для Тензорного Кота писать вверх ногами — это всего лишь вопрос выбора правильной системы координат.*

Эти пары «вход + цель» генерируются автоматически, без ручной разметки. Та же идея применяется к разным типам данных, таким как изображения (предсказание отсутствующих фрагментов) или аудио.

**Реальные применения самостоятельного обучения:**
*   **Языковые модели** (GPT, LLaMA, Claude)
*   **Компьютерное зрение** (CLIP, DINO)
*   **Аудио и речь** (Wav2Vec 2.0)
*   **Мультимодальные модели** (Gemini, CLIP)
*   **Предобучение (фундаментальные модели)**

**Основная идея**
Модель обучается на автоматически сгенерированных задачах, где «правильный ответ» извлекается непосредственно из самих данных. Это дает нам масштабируемость, способность к обобщению и основу для большинства современных генеративных и языковых систем.

#### Сводка по парадигмам обучения

| Парадигма                 | Как учится модель                                            |
|---------------------------|--------------------------------------------------------------|
| Обучение с учителем       | На размеченных данных (вход → правильный ответ)              |
| Обучение без учителя      | На неразмеченных данных (модель сама находит структуру)      |
| Обучение с подкреплением  | Через взаимодействие со средой через награды и штрафы        |
| Самостоятельное обучение | На неразмеченных данных, где задачи генерируются из них же   |

#### Что еще существует?

Помимо этих четырех, существуют и другие подходы (частично-контролируемое, активное, онлайн-обучение и т. д.). Они редко рассматриваются как самостоятельные парадигмы, потому что обычно являются гибридами или вариациями основных стратегий, которые мы уже рассмотрели. Для понимания сути машинного обучения — достаточно освоить эти четыре.

В следующей части мы погрузимся в то, что такое нейронная сеть на самом деле: нейроны, веса, связи. Как она «учится»? Зачем ей вообще нужны слои? И какое отношение куча чисел имеет к пониманию языка, изображений или... реальности?

Мы снимем слой за слоем — и попытаемся ответить на единственный вопрос, который имеет значение:

**Так есть ли здесь хоть какая-то магия... или это просто замаскированная математика?**

https://medium.com/@paul.ilvez/how-ai-learns-no-formulas-but-plenty-of-cats-fc43471add24
