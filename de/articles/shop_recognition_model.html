<h2>Training eines OpenAI-Modells zur Klassifizierung von Webseiten</h2>
<h2>Einführung</h2>
<p>Training eines OpenAI-Modells, um festzustellen, ob eine Seite ein Online-Shop ist.</p>
<ul>
<li>Datenvorbereitung,</li>
<li>Text-Tokenisierung,</li>
<li>Senden von Daten zum Training</li>
<li>Modelltest.</li>
</ul>
<h2>Schritt 1: Registrierung und Einrichtung der OpenAI API</h2>
<p>Um mit der OpenAI API zu arbeiten, müssen Sie sich auf der OpenAI-Plattform registrieren und einen API-Schlüssel erhalten. Dieser Schlüssel wird zur Authentifizierung beim Aufruf von API-Methoden verwendet.</p>
<pre class="line-numbers"><code class="language-python">import openai

# API-Schlüssel festlegen
openai.api_key = 'your-api-key'
</code></pre>
<h2>Schritt 2: Datenvorbereitung</h2>
<p>Um das Modell zu trainieren, müssen Sie einen Datensatz vorbereiten, der Beispiele von Webseiten enthält,
sowohl von Shops als auch von Nicht-Shops.
Jeder Eintrag muss den Text der Seite und ein entsprechendes Label (<code>positive</code> für Shops und <code>negative</code> für Nicht-Shops) enthalten.</p>
<p>Beispiel JSON-Datei:</p>
<pre class="line-numbers"><code class="language-json">[
    {
        "text": "&lt;html&gt;&lt;body&gt;&lt;h1&gt;Willkommen in unserem Online-Shop&lt;/h1&gt;&lt;p&gt;Wir bieten eine große Auswahl an Produkten zu wettbewerbsfähigen Preisen. Besuchen Sie unseren Shop noch heute!&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;",
        "label": "positive"
    },
    {
        "text": "&lt;html&gt;&lt;body&gt;&lt;h1&gt;Über uns&lt;/h1&gt;&lt;p&gt;Wir sind ein führender Anbieter von Qualitätsdienstleistungen. Kontaktieren Sie uns für weitere Informationen.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;",
        "label": "negative"
    }
]
</code></pre>
<h2>Schritt 3: Text-Tokenisierung</h2>
<p>Bevor die Daten an das OpenAI-Modell gesendet werden, muss der Text tokenisiert werden.
Tokenisierung ist der Prozess des Aufteilens von Text in einzelne Wörter oder Token.
In Python können Sie Bibliotheken wie NLTK, spaCy oder Tokenizer aus der Transformers-Bibliothek verwenden.</p>
<p>Beispiel Tokenisierung mit NLTK:</p>
<pre class="line-numbers"><code class="language-python">import nltk
from nltk.tokenize import word_tokenize

# Beispieltext
text = "Dies ist ein Beispieltext zur Tokenisierung."

# Text-Tokenisierung
tokens = word_tokenize(text)
tokenized_text = ' '.join(tokens)
print(tokenized_text)
</code></pre>
<h2>Schritt 4: Senden von Daten zum Training</h2>
<p>Nach der Tokenisierung des Textes können Sie die Daten zum Trainieren des OpenAI-Modells senden.
Hier ist ein Beispielcode zum Senden von Daten:</p>
<pre class="line-numbers"><code class="language-python">import openai

def train_model(data, positive=True):
    try:
        response = openai.Train.create(
            model="text-davinci-003",
            documents=[entry["text"] for entry in data],
            labels=["positive" if positive else "negative"] * len(data),
            show_progress=True
        )
        return response.id
    except Exception as ex:
        print("Während des Trainings ist ein Fehler aufgetreten:", ex)
        return None

# Beispielverwendung
data = [
    {"text": "Text der ersten Webseite...", "label": "positive"},
    {"text": "Text der zweiten Webseite...", "label": "negative"}
]

job_id = train_model(data, positive=True)
print("Job-ID:", job_id)
</code></pre>
<h2>Schritt 5: Modelltest</h2>
<p>Nach dem Training des Modells muss es mit einem Testdatensatz getestet werden.
Hier ist ein Beispielcode zum Testen:</p>
<pre class="line-numbers"><code class="language-python">def test_model(test_data):
    try:
        predictions = []
        for entry in test_data:
            response = openai.Completion.create(
                model="text-davinci-003",
                prompt=entry["text"],
                max_tokens=1
            )
            prediction = response.choices[0].text.strip()
            predictions.append(prediction)
        return predictions
    except Exception as ex:
        print("Während des Tests ist ein Fehler aufgetreten:", ex)
        return None

# Beispielverwendung
test_data = [
    {"text": "Text der Test-Webseite...", "label": "positive"},
    {"text": "Text einer anderen Testseite...", "label": "negative"}
]

predictions = test_model(test_data)
print("Vorhersagen:", predictions)
</code></pre>
<h2>Schritt 6: Fehlerbehandlung und Modellverbesserung</h2>
<p>Wenn das Modell falsche Vorhersagen liefert, können Sie es verbessern, indem Sie
mehr Daten hinzufügen oder Trainingsparameter ändern. Sie können auch Feedback zur Fehleranalyse verwenden.</p>
<p>Beispiel Fehlerbehandlung:</p>
<pre class="line-numbers"><code class="language-python">def handle_errors(predictions, test_data):
    for pred, entry in zip(predictions, test_data):
        if pred != entry["label"]:
            print(f"Falsche Vorhersage für Seite '{entry['name']}': Vorhergesagt {pred}, Tatsächlich {entry['label']}")

# Beispielverwendung
handle_errors(predictions, test_data)
</code></pre>