<h1>Training an OpenAI model to classify web pages</h1>
<h2>Introduction</h2>
<p>Training an OpenAI model to determine if a page is an online store.</p>
<ul>
<li>data preparation,</li>
<li>text tokenization,</li>
<li>sending data for training</li>
<li>model testing.</li>
</ul>
<h2>Step 1: OpenAI API Registration and Configuration</h2>
<p>To start using the OpenAI API, you need to register on the OpenAI platform and obtain an API key. This key will be used for authentication when calling API methods.</p>
<pre class="line-numbers"><code class="language-python">
import openai

# Set the API key
openai.api_key = 'your-api-key'
</code></pre>
<h2>Step 2: Data Preparation</h2>
<p>To train the model, you need to prepare a dataset that will contain examples of web pages,
both stores and non-stores.
Each entry must include the page text and the corresponding label (<code>positive</code> for stores and <code>negative</code> for non-stores).</p>
<p>Example JSON file:</p>
<pre class="line-numbers"><code class="language-json">
[
    {
        "text": "&lt;html&gt;&lt;body&gt;&lt;h1&gt;Welcome to our online store&lt;/h1&gt;&lt;p&gt;We offer a wide range of products at competitive prices. Visit our store today!&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;",
        "label": "positive"
    },
    {
        "text": "&lt;html&gt;&lt;body&gt;&lt;h1&gt;About us&lt;/h1&gt;&lt;p&gt;We are a leading provider of quality services. Contact us for more information.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;",
        "label": "negative"
    }
]
</code></pre>
<h2>Step 3: Text Tokenization</h2>
<p>Before sending data to the OpenAI model, the text must be tokenized.
Tokenization is the process of breaking down text into individual words or tokens.
In Python, you can use libraries such as NLTK, spaCy, or the tokenizers from the transformers library.</p>
<p>Example of tokenization with NLTK:</p>
<pre class="line-numbers"><code class="language-python">
import nltk
from nltk.tokenize import word_tokenize

# Example text
text = "This is an example text for tokenization."

# Tokenize the text
tokens = word_tokenize(text)
tokenized_text = ' '.join(tokens)
print(tokenized_text)
</code></pre>
<h2>Step 4: Sending Data for Training</h2>
<p>After tokenizing the text, you can send the data to train the OpenAI model.
Here is an example code for sending data:</p>
<pre class="line-numbers"><code class="language-python">
import openai

def train_model(data, positive=True):
    try:
        response = openai.Train.create(
            model="text-davinci-003",
            documents=[entry["text"] for entry in data],
            labels=["positive" if positive else "negative"] * len(data),
            show_progress=True
        )
        return response.id
    except Exception as ex:
        print("An error occurred during training:", ex)
        return None

# Example usage
data = [
    {"text": "Text from the first web page...", "label": "positive"},
    {"text": "Text from the second web page...", "label": "negative"}
]

job_id = train_model(data, positive=True)
print("Job ID:", job_id)
</code></pre>
<h2>Step 5: Model Testing</h2>
<p>After training the model, you need to test it on a test dataset.
Here is an example code for testing:</p>
<pre class="line-numbers"><code class="language-python">
def test_model(test_data):
    try:
        predictions = []
        for entry in test_data:
            response = openai.Completion.create(
                model="text-davinci-003",
                prompt=entry["text"],
                max_tokens=1
            )
            prediction = response.choices[0].text.strip()
            predictions.append(prediction)
        return predictions
    except Exception as ex:
        print("An error occurred during testing:", ex)
        return None

# Example usage
test_data = [
    {"text": "Text from a test web page...", "label": "positive"},
    {"text": "Text from another test page...", "label": "negative"}
]

predictions = test_model(test_data)
print("Predictions:", predictions)
</code></pre>
<h2>Step 6: Error Handling and Model Improvement</h2>
<p>If the model makes incorrect predictions, you can improve it
by adding more data or by changing the training parameters. You can also use comments to analyze errors.</p>
<p>Example of error handling:</p>
<pre class="line-numbers"><code class="language-python">
def handle_errors(predictions, test_data):
    for pred, entry in zip(predictions, test_data):
        if pred != entry["label"]:
            print(f"Incorrect prediction for page '{entry['name']}': Predicted {pred}, Actual {entry['label']}")

# Example usage
handle_errors(predictions, test_data)
</code></pre>
