# כיצד ללמד רשת עצבית לעבוד עם ידיים: יצירת סוכן בינה מלאכותית מלא עם MCP ו-LangGraph בשעה


חברים, ברוכים הבאים! אני מקווה שהתגעגעתם.

בחודשיים האחרונים שקעתי עמוק בחקר שילוב סוכני בינה מלאכותית בפרויקטי הפייתון שלי. בתהליך צברתי ידע מעשי ותצפיות רבות, שפשוט חבל לא לשתף. לכן היום אני חוזר ל-Habr – עם נושא חדש, מבט רענן ובכוונה לכתוב לעיתים קרובות יותר.

על הפרק – LangGraph ו-MCP: כלים שבאמצעותם ניתן ליצור סוכני בינה מלאכותית שימושיים באמת.

אם בעבר התווכחנו איזו רשת עצבית עונה טוב יותר ברוסית, הרי שהיום שדה הקרב עבר למשימות יישומיות יותר: מי מתמודד טוב יותר עם תפקיד סוכן בינה מלאכותית? אילו פריימוורקים באמת מפשטים את הפיתוח? וכיצד לשלב את כל הטוב הזה בפרויקט אמיתי?

אבל לפני שנצלול לפרקטיקה ולקוד, בואו נבין את המושגים הבסיסיים. במיוחד שניים מרכזיים: **סוכני בינה מלאכותית ו-MCP**. בלעדיהם, השיחה על LangGraph תהיה לא שלמה.

### סוכני בינה מלאכותית במילים פשוטות

סוכני בינה מלאכותית הם לא רק צ'אטבוטים "משודרגים". הם מייצגים ישויות מורכבות ואוטונומיות יותר, בעלות שתי תכונות חשובות ביותר:

1.  **יכולת אינטראקציה ותיאום**

    סוכנים מודרניים מסוגלים לחלק משימות למשימות משנה, לקרוא לסוכנים אחרים, לבקש נתונים חיצוניים, ולעבוד בצוות. זה כבר לא עוזר בודד, אלא מערכת מבוזרת, שבה כל רכיב יכול לתרום את חלקו.

2.  **גישה למשאבים חיצוניים**

    סוכן בינה מלאכותית אינו מוגבל עוד למסגרת דיאלוג. הוא יכול לגשת למסדי נתונים, לבצע קריאות API, ליצור אינטראקציה עם קבצים מקומיים, מאגרי ידע וקטוריים ואף להריץ פקודות בטרמינל. כל זה התאפשר הודות להופעת MCP – רמה חדשה של אינטגרציה בין המודל לסביבה.

---

אם לדבר בפשטות: **MCP הוא גשר בין רשת עצבית לסביבתה**. הוא מאפשר למודל "להבין" את הקשר המשימה, לגשת לנתונים, לבצע קריאות ולגבש פעולות מנומקות, במקום פשוט להוציא תגובות טקסטואליות.

**בואו נדמיין אנלוגיה:**

*   יש לך **רשת עצבית** – היא יודעת להסיק מסקנות ולייצר טקסטים.
*   יש **נתונים וכלים** – מסמכים, API, מאגרי ידע, טרמינל, קוד.
*   ויש **MCP** – זהו ממשק המאפשר למודל ליצור אינטראקציה עם מקורות חיצוניים אלה כאילו היו חלק מעולמו הפנימי.

**ללא MCP:**

המודל הוא מנוע דיאלוג מבודד. אתה מזין לו טקסט – הוא מגיב. וזהו.

**עם MCP:**

המודל הופך ל**מבצע משימות** מלא:

*   מקבל גישה למבני נתונים ו-API;
*   מבצע קריאות לפונקציות חיצוניות;
*   מתמצא במצב הנוכחי של הפרויקט או היישום;
*   יכול לזכור, לעקוב ולשנות את ההקשר במהלך הדיאלוג;
*   משתמש בהרחבות כגון כלי חיפוש, מריצי קוד, בסיס נתונים של הטמעות וקטוריות וכו'.

במובן הטכני, **MCP הוא פרוטוקול לאינטראקציה בין LLM לסביבתו**, כאשר ההקשר מסופק בצורת אובייקטים מובנים (במקום טקסט "גולמי"), והקריאות מנוסחות כפעולות אינטראקטיביות (לדוגמה, קריאת פונקציות, שימוש בכלים או פעולות סוכן). זה מה שהופך מודל רגיל ל**סוכן בינה מלאכותית אמיתי**, המסוגל לעשות יותר מסתם "לדבר".

### ועכשיו – לעבודה!

כעת, לאחר שהבנו את המושגים הבסיסיים, הגיוני לשאול: "כיצד ליישם את כל זה בפועל בפייתון?"

כאן נכנס לתמונה **LangGraph** – פריימוורק עוצמתי לבניית גרפי מצבים, התנהגות סוכנים ושרשרות חשיבה. הוא מאפשר "לתפור" את לוגיקת האינטראקציה בין סוכנים, כלים ומשתמש, וליצור ארכיטקטורת AI חיה המסתגלת למשימות.

בסעיפים הבאים נראה כיצד:

*   בונים סוכן מאפס;
*   יוצרים מצבים, מעברים ואירועים;
*   משלבים פונקציות וכלים;
*   וכיצד כל המערכת האקולוגית הזו פועלת בפרויקט אמיתי.

### קצת תיאוריה: מהו LangGraph?

לפני שנתחיל בפרקטיקה, יש לומר כמה מילים על הפריימוורק עצמו.

**LangGraph** הוא פרויקט של צוות **LangChain**, אותם אלה שהציעו לראשונה את הרעיון של "שרשרות" (chains) אינטראקציה עם LLM. אם בעבר הדגש העיקרי היה על צינורות לינאריים או מסתעפים מותנים (langchain.chains), הרי שכעת המפתחים מהמרים על **מודל גרפי**, ו-LangGraph הוא מה שהם ממליצים כ"ליבה" החדשה לבניית מערכות AI מורכבות.

**LangGraph** הוא פריימוורק לבניית מכונות מצבים סופיות וגרפי מצבים, שבהם כל **צומת** מייצג חלק מלוגיקת הסוכן: קריאת מודל, כלי חיצוני, תנאי, קלט משתמש וכו'.

### איך זה עובד: גרפים וצמתים

מבחינה קונספטואלית, LangGraph בנוי על הרעיונות הבאים:

*   **גרף** – הוא מבנה המתאר את נתיבי הביצוע האפשריים של הלוגיקה. ניתן לחשוב עליו כמפה: מנקודה אחת ניתן לעבור לאחרת בהתאם לתנאים או לתוצאת הביצוע.
*   **צמתים** – הם שלבים ספציפיים בתוך הגרף. כל צומת מבצע פונקציה כלשהי: קורא למודל, קורא ל-API חיצוני, בודק תנאי או פשוט מעדכן את המצב הפנימי.
*   **מעברים בין צמתים** – זוהי לוגיקת הניתוב: אם תוצאת השלב הקודם היא כזו וכזו, אז הולכים לשם.
*   **מצב** – מועבר בין צמתים ואוגר את כל מה שצריך: היסטוריה, מסקנות ביניים, קלט משתמש, תוצאות פעולת כלים וכו'.

כך אנו מקבלים **מנגנון גמיש לשליטה בלוגיקת הסוכן**, שבו ניתן לתאר תרחישים פשוטים ומורכבים מאוד: לולאות, תנאים, פעולות מקבילות, קריאות מקוננות ועוד הרבה.

### למה זה נוח?

LangGraph מאפשר לבנות **לוגיקה שקופה, ניתנת לשחזור וניתנת להרחבה**:

*   קל לניפוי באגים;
*   קל להדמיה;
*   קל להתאמה למשימות חדשות;
*   קל לשלב כלים חיצוניים ופרוטוקולי MCP.

בעצם, LangGraph הוא **"המוח" של הסוכן**, כאשר כל שלב מתועד, ניתן לשליטה וניתן לשינוי ללא כאוס ו"קסם".

### ובכן, מספיק תיאוריה!

אפשר עוד לדבר ארוכות על גרפים, מצבים, הרכבת לוגיקה ויתרונות LangGraph על פני צינורות קלאסיים. אבל, כפי שמראה הניסיון, עדיף לראות פעם אחת בקוד.

**הגיע הזמן לעבור לפרקטיקה.** הבא בתור – דוגמה בפייתון: ניצור סוכן AI פשוט אך שימושי המבוסס על LangGraph שישתמש בכלים חיצוניים, זיכרון ויקבל החלטות בעצמו.

### הכנה: רשתות עצביות בענן ומקומיות

כדי להתחיל ליצור סוכני AI, אנו זקוקים קודם כל ל**מוח** – מודל שפה. כאן יש שתי גישות:

*   **להשתמש בפתרונות ענן**, שבהם הכל מוכן "מהקופסה";
*   או **להעלות את המודל באופן מקומי** – לאוטונומיה וסודיות מלאה.

בואו נבחן את שתי האפשרויות.

#### שירותי ענן: מהירים ונוחים

הדרך הפשוטה ביותר היא לנצל את היכולות של ספקים גדולים: OpenAI, Anthropic, ולהשתמש...

### היכן להשיג מפתחות ואסימונים:

*   **OpenAI** – ChatGPT ומוצרים אחרים;
*   **Anthropic** – Claude;
*   **OpenRouter.ai** – עשרות מודלים (אסימון אחד – מודלים רבים באמצעות API תואם OpenAI);
*   **Amvera Cloud** – היכולת לחבר LLAMA עם תשלום ברובלים ופרוקסי מובנה ל-OpenAI ו-Anthropic.

נתיב זה נוח, במיוחד אם אתה:

*   לא רוצה להגדיר תשתית;
*   מפתח עם דגש על מהירות;
*   עובד עם משאבים מוגבלים.

### מודלים מקומיים: שליטה מלאה

אם **פרטיות, עבודה ללא אינטרנט** חשובים לך, או שאתה רוצה לבנות **סוכנים אוטונומיים לחלוטין**, אז הגיוני לפרוס את הרשת העצבית באופן מקומי.

**יתרונות עיקריים:**

*   **סודיות** – הנתונים נשארים אצלך;
*   **עבודה ללא אינטרנט** – שימושי ברשתות מבודדות;
*   **ללא מנויים ואסימונים** – חינם לאחר ההגדרה.

**החסרונות ברורים:**

*   דרישות משאבים (במיוחד לזיכרון וידאו);
*   ההגדרה יכולה לקחת זמן;
*   חלק מהמודלים קשים לפריסה ללא ניסיון.

עם זאת, ישנם כלים המפשטים את ההפעלה המקומית. אחד הטובים ביותר כיום הוא **Ollama**.

### פריסת LLM מקומי באמצעות Ollama + Docker

אנו נכין הפעלה מקומית של מודל Qwen 2.5 (qwen2.5:32b) באמצעות קונטיינר Docker ומערכת Ollama. זה יאפשר לשלב את הרשת העצבית עם MCP ולהשתמש בה בסוכני LangGraph משלך.

אם משאבי המחשוב של המחשב או השרת שלך אינם מספיקים לעבודה עם גרסה זו של המודל, תוכל תמיד לבחור רשת עצבית פחות "זוללת משאבים" – תהליך ההתקנה וההפעלה יישאר דומה.

**התקנה מהירה (סיכום שלבים)**

1.  **התקן Docker + Docker Compose**
2.  **צור מבנה פרויקט:**
```bash
mkdir qwen-local && cd qwen-local
```
3.  **צור `docker-compose.yml`**
(אפשרות אוניברסלית, GPU מזוהה אוטומטית)

```yaml
services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama_qwen
    ports:
      - "11434:11434"
    volumes:
      - ./ollama_data:/root/.ollama
      - /tmp:/tmp
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_ORIGINS=*
    restart: unless-stopped
```

4.  **הפעל את הקונטיינר:**
```bash
docker compose up -d
```

5.  **הורד את המודל:**
```bash
docker exec -it ollama_qwen ollama pull qwen2.5:32b
```

6.  **בדוק פעולה באמצעות API:**
```bash
curl http://localhost:11434/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model": "qwen2.5:32b", "prompt": "שלום!", "stream": false}'
```
*(תמונה עם תוצאת ביצוע פקודת curl)*

7.  **שילוב עם פייתון:**
```python
import requests

def query(prompt):
    res = requests.post("http://localhost:11434/api/generate", json={
        "model": "qwen2.5:32b",
        "prompt": prompt,
        "stream": False
    })
    return res.json()['response']

print(query("הסבר שזירה קוונטית"))
```
כעת יש לך LLM מקומי מלא, מוכן לעבוד עם MCP ו-LangGraph.

**מה הלאה?**

יש לנו בחירה בין מודלים בענן למודלים מקומיים, ולמדנו כיצד לחבר את שניהם. החלק המעניין ביותר לפנינו – **יצירת סוכני AI ב-LangGraph**, המשתמשים במודל הנבחר, בזיכרון, בכלים ובלוגיקה משלהם.

**בואו נעבור לחלק הטעים ביותר – קוד ופרקטיקה!**

--- 

לפני שנעבור לפרקטיקה, חשוב להכין את סביבת העבודה. אני מניח שאתה כבר מכיר את יסודות הפייתון, יודע מהן ספריות ותלויות, ומבין מדוע להשתמש בסביבה וירטואלית.

אם כל זה חדש לך – אני ממליץ קודם לעבור קורס קצר או מדריך על יסודות הפייתון, ולאחר מכן לחזור למאמר.

#### שלב 1: יצירת סביבה וירטואלית

צור סביבה וירטואלית חדשה בתיקיית הפרויקט:
```bash
python -m venv venv
source venv/bin/activate  # עבור לינוקס/macOS
virtualenv\Scripts\activate   # עבור Windows
```

#### שלב 2: התקנת תלויות

צור קובץ `requirements.txt` והוסף לו את השורות הבאות:
```
langchain==0.3.26
langchain-core==0.3.69
langchain-deepseek==0.1.3
langchain-mcp-adapters==0.1.9
langchain-ollama==0.3.5
langchain-openai==0.3.28
langgraph==0.5.3
langgraph-checkpoint==2.1.1
langgraph-prebuilt==0.5.2
langgraph-sdk==0.1.73
langsmith==0.4.8
mcp==1.12.0
ollama==0.5.1
openai==1.97.0
```

> ⚠️ **הגרסאות הנוכחיות מצוינות נכון ל-21 ביולי 2025.** ייתכן שהן השתנו מאז הפרסום – **בדוק רלוונטיות לפני ההתקנה.**

לאחר מכן התקן את התלויות:
```bash
pip install -r requirements.txt```

#### שלב 3: הגדרת משתני סביבה

צור קובץ `.env` בשורש הפרויקט והוסף לו את מפתחות ה-API הדרושים:
```
OPENAI_API_KEY=sk-proj-1234
DEEPSEEK_API_KEY=sk-123
OPENROUTER_API_KEY=sk-or-v1-123
BRAVE_API_KEY=BSAj123K1bvBGpH1344tLwc
```

**מטרת המשתנים:**

*   **OPENAI_API_KEY** – מפתח לגישה למודלי GPT מ-OpenAI;
*   **DEEPSEEK_API_KEY** – מפתח לשימוש במודלי Deepseek;
*   **OPENROUTER_API_KEY** – מפתח יחיד לגישה למודלים רבים באמצעות OpenRouter

---
חלק מכלי MCP (לדוגמה, `brave-web-search`) דורשים מפתח כדי לעבוד. בלעדיו, הם פשוט לא יופעלו.

**ומה אם אין לך מפתחות API?**

אין בעיה. אתה יכול להתחיל פיתוח עם מודל מקומי (לדוגמה, באמצעות Ollama), מבלי לחבר שום שירות חיצוני. במקרה זה, אין צורך ליצור את קובץ `.env` כלל.

מוכן! כעת יש לנו את כל מה שצריך כדי להתחיל – סביבה מבודדת, תלויות, ובמידת הצורך, גישה לרשתות עצביות בענן ושילובי MCP.

בהמשך – נפעיל את סוכן ה-LLM שלנו בדרכים שונות.

### הפעלה פשוטה של סוכני LLM באמצעות LangGraph: אינטגרציה בסיסית

נתחיל מהפשוט ביותר: כיצד "לחבר את המוח" לסוכן עתידי. ננתח את הדרכים הבסיסיות להפעלת מודלי שפה (LLM) באמצעות LangChain, כך שבשלב הבא נוכל לעבור לשילוב עם LangGraph ובניית סוכן AI מלא.

#### ייבוא
```python
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_ollama import ChatOllama
from langchain_deepseek import ChatDeepSeek
```
*   `os` ו-`load_dotenv()` – לטעינת משתנים מקובץ `.env`.
*   `ChatOpenAI`, `ChatOllama`, `ChatDeepSeek` – עטיפות לחיבור מודלי שפה באמצעות LangChain.

> 💡 אם אתה משתמש בגישות חלופיות לעבודה עם תצורות (לדוגמה, Pydantic Settings), תוכל להחליף את `load_dotenv()` בשיטה המוכרת לך.

#### טעינת משתני סביבה
```python
load_dotenv()
```
זה יטען את כל המשתנים מ-`.env`, כולל מפתחות לגישה ל-API של OpenAI, DeepSeek, OpenRouter ואחרים.

#### פונקציות פשוטות לקבלת LLM

**OpenAI**
```python
def get_openai_llm():
    return ChatOpenAI(model="gpt-4o-mini", api_key=os.getenv("OPENAI_API_KEY"))
```
אם המשתנה `OPENAI_API_KEY` מוגדר נכון, LangChain יחליף אותו אוטומטית – ציון מפורש של `api_key=...` כאן הוא אופציונלי.

**DeepSeek**
```python
def get_deepseek_llm():
    # ...
```
באופן דומה, אך באמצעות עטיפת `ChatDeepSeek`.

**OpenRouter (ו-API תואמים אחרים)**
```python
def get_openrouter_llm(model="moonshotai/kimi-k2:free"):
    return ChatOpenAI(
        model=model,
        api_key=os.getenv("OPENROUTER_API_KEY"),
        base_url="https://openrouter.ai/api/v1",
        temperature=0
    )
```
**תכונות:**

*   `ChatOpenAI` משמש, למרות שהמודל אינו מ-OpenAI – מכיוון ש-OpenRouter משתמש באותו פרוטוקול.
*   `base_url` הוא חובה: הוא מצביע על OpenRouter API.
*   המודל `moonshotai/kimi-k2:free` נבחר כאחת האפשרויות המאוזנות ביותר מבחינת איכות ומהירות בזמן כתיבת המאמר.
*   מפתח ה-API של `OpenRouter` חייב להיות מועבר במפורש – החלפה אוטומטית אינה פועלת כאן.

#### מיני-מבחן: בדיקת פעולת המודל
```python
if __name__ == "__main__":
    llm = get_openrouter_llm(model="moonshotai/kimi-k2:free")
    response = llm.invoke("מי אתה?")
    print(response.content)
```
*(תמונה עם תוצאת הביצוע: `אני עוזר AI שנוצר על ידי Moonshot AI...`)*

אם הכל מוגדר נכון, תקבל תגובה משמעותית מהמודל. מזל טוב – הצעד הראשון נעשה!

### אבל זה עדיין לא סוכן

בשלב הנוכחי, חיברנו LLM וביצענו קריאה פשוטה. זה דומה יותר לצ'אטבוט קונסולה מאשר לסוכן AI.

**למה?**

*   אנו כותבים **קוד סינכרוני, לינארי** ללא לוגיקת מצב או מטרות.
*   הסוכן אינו מקבל החלטות, אינו זוכר הקשר ואינו משתמש בכלים.
*   MCP ו-LangGraph עדיין לא מעורבים.

**מה הלאה?**

בהמשך, ניישם **סוכן AI מלא** באמצעות **LangGraph** – תחילה ללא MCP, כדי להתמקד בארכיטקטורה, במצבים ובלוגיקה של הסוכן עצמו.

בואו נצלול למכניקת סוכנים אמיתית. קדימה!

### סוכן סיווג משרות: מתיאוריה לפרקטיקה

...מושגי LangGraph בפועל וליצור כלי שימושי עבור פלטפורמות משאבי אנוש ובורסות פרילנסרים.

#### משימת הסוכן

הסוכן שלנו מקבל כקלט תיאור טקסטואלי של משרה פנויה או שירות ומבצע סיווג תלת-שכבתי:

1.  **סוג עבודה**: עבודת פרויקט או משרה קבועה
2.  **קטגוריית מקצוע**: מתוך 45+ התמחויות מוגדרות מראש
3.  **סוג חיפוש**: האם אדם מחפש עבודה או מחפש מבצע

התוצאה מוחזרת בפורמט JSON מובנה עם ציון ביטחון עבור כל סיווג.

#### 📈 ארכיטקטורת סוכן ב-LangGraph

בהתאם לעקרונות LangGraph, אנו יוצרים **גרף מצבים** של ארבעה צמתים:

- תיאור קלט
- ↓
- צומת סיווג סוג עבודה
- ↓
- צומת סיווג קטגוריה
- ↓
- צומת קביעת סוג חיפוש
- ↓
- צומת חישוב ביטחון
- ↓
- תוצאת JSON

כל צומת הוא **פונקציה מיוחדת** אשר:

*   מקבלת את מצב הסוכן הנוכחי
*   מבצעת את חלקה בניתוח
*   מעדכנת את המצב ומעבירה אותו הלאה

#### ניהול מצב

אנו מגדירים את **מבנה הזיכרון של הסוכן** באמצעות `TypedDict`:

```python
from typing import TypedDict, Dict

class State(TypedDict):
    """מצב סוכן לאחסון מידע על תהליך הסיווג"""
    description: str
    job_type: str
    category: str
    search_type: str
    confidence_scores: Dict[str, float]
    processed: bool
```

זהו **זיכרון העבודה של הסוכן** – כל מה שהוא זוכר ואוגר במהלך הניתוח. בדומה לאופן שבו מומחה אנושי שומר בראשו את הקשר המשימה בעת ניתוח מסמך.

בואו נסתכל על הקוד המלא, ולאחר מכן נתמקד בנקודות העיקריות.

```python
import asyncio
import json
from enum import Enum
from typing import TypedDict, Dict, Any, List

from langgraph.graph import StateGraph, END
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage

# קטגוריות מקצועות
CATEGORIES = [
    "אנימטור דו-ממדי", "אנימטור תלת-ממדי", "מודלר תלת-ממדי",
    "אנליסט עסקי", "מפתח בלוקצ'יין", ...
]

class JobType(Enum):
    PROJECT = "עבודת פרויקט"
    PERMANENT = "עבודה קבועה"

class SearchType(Enum):
    LOOKING_FOR_WORK = "מחפש עבודה"
    LOOKING_FOR_PERFORMER = "מחפש מבצע"

class State(TypedDict):
    """מצב סוכן לאחסון מידע על תהליך הסיווג"""
    description: str
    job_type: str
    category: str
    search_type: str
    confidence_scores: Dict[str, float]
    processed: bool

class VacancyClassificationAgent:
    """סוכן אסינכרוני לסיווג משרות ושירותים"""

    def __init__(self, model_name: str = "gpt-4o-mini", temperature: float = 0.1):
        """אתחול סוכן"""
        self.llm = ChatOpenAI(model=model_name, temperature=temperature)
        self.workflow = self._create_workflow()

    def _create_workflow(self) -> StateGraph:
        """יוצר את זרימת העבודה של הסוכן המבוססת על LangGraph"""
        workflow = StateGraph(State)
        
        # הוספת צמתים לגרף
        workflow.add_node("job_type_classification", self._classify_job_type)
        workflow.add_node("category_classification", self._classify_category)
        workflow.add_node("search_type_classification", self._classify_search_type)
        workflow.add_node("confidence_calculation", self._calculate_confidence)
        
        # הגדרת רצף ביצוע הצמתים
        workflow.set_entry_point("job_type_classification")
        workflow.add_edge("job_type_classification", "category_classification")
        workflow.add_edge("category_classification", "search_type_classification")
        workflow.add_edge("search_type_classification", "confidence_calculation")
        workflow.add_edge("confidence_calculation", END)
        
        return workflow.compile()

    async def _classify_job_type(self, state: State) -> Dict[str, Any]:
        """צומת לקביעת סוג עבודה: פרויקט או קבוע"""
        # ... (היישום ממשיך)
        
    async def _classify_category(self, state: State) -> Dict[str, Any]:
        """צומת לקביעת קטגוריית מקצוע"""
        # ... (היישום ממשיך)
        
    async def _classify_search_type(self, state: State) -> Dict[str, Any]:
        """צומת לקביעת סוג חיפוש"""
        # ... (היישום ממשיך)

    async def _calculate_confidence(self, state: State) -> Dict[str, Any]:
        """צומת לחישוב רמת הביטחון בסיווג"""
        # ... (היישום ממשיך)

    def _find_closest_category(self, predicted_category: str) -> str:
        """מוצא את הקטגוריה הקרובה ביותר מתוך רשימת הקטגוריות הזמינות"""
        # ... (היישום ממשיך)

    async def classify(self, description: str) -> Dict[str, Any]:
        """שיטה ראשית לסיווג משרה/שירות"""
        initial_state = {
            "description": description,
            "job_type": "",
            "category": "",
            "search_type": "",
            "confidence_scores": {},
            "processed": False
        }
        
        # הפעל את זרימת העבודה
        result = await self.workflow.ainvoke(initial_state)
        
        # צור את תגובת ה-JSON הסופית
        classification_result = {
            "job_type": result["job_type"],
            "category": result["category"],
            "search_type": result["search_type"],
            "confidence_scores": result["confidence_scores"],
            "success": result["processed"]
        }
        return classification_result

async def main():
    """הדגמת פעולת הסוכן"""
    agent = VacancyClassificationAgent()
    
    test_cases = [
        "דרוש מפתח פייתון ליצירת יישום ווב ב-Django. עבודה קבועה.",
        "מחפש הזמנות ליצירת לוגואים וזהות תאגידית. אני עובד ב-Adobe Illustrator.",
        "דרוש אנימטור תלת-ממדי לפרויקט קצר טווח ליצירת פרסומת.",
        "קורות חיים: משווק מנוסה, מחפש עבודה מרחוק בתחום השיווק הדיגיטלי",
        "מחפשים מפתח פרונטאנד React לצוות שלנו על בסיס קבוע"
    ]
    
    print("🤖 הדגמת פעולת סוכן סיווג משרות\n")
    for i, description in enumerate(test_cases, 1):
        print(f"--- מבחן {i}: ---")
        print(f"תיאור: {description}")
        try:
            result = await agent.classify(description)
            print("תוצאת סיווג:")
            print(json.dumps(result, ensure_ascii=False, indent=2))
        except Exception as e:
            print(f"❌ שגיאה: {e}")
        print("-" * 80)

if __name__ == "__main__":
    asyncio.run(main())

```
*(...שאר הקוד עם יישומי השיטות הוצג במאמר...)*

### יתרונות מפתח של הארכיטקטורה
1.  **מודולריות** – כל צומת פותר משימה אחת, קל לבדוק ולשפר בנפרד
2.  **הרחבה** – ניתן להוסיף תכונות ניתוח חדשות באופן הצהרתי
3.  **שקיפות** – כל תהליך קבלת ההחלטות מתועד וניתן למעקב
4.  **ביצועים** – עיבוד אסינכרוני של בקשות מרובות
5.  **אמינות** – טיפול בשגיאות מובנה ושחזור

### תועלת אמיתית
סוכן כזה יכול לשמש ב:
*   **פלטפורמות משאבי אנוש** לסיווג אוטומטי של קורות חיים ומשרות פנויות
*   **בורסות פרילנסרים** לשיפור חיפוש והמלצות
*   **מערכות פנימיות** של חברות לעיבוד בקשות ופרויקטים
*   **פתרונות אנליטיים** לחקר שוק העבודה

### MCP בפעולה: יצירת סוכן עם מערכת קבצים וחיפוש אינטרנט
לאחר שהבנו את העקרונות הבסיסיים של LangGraph ויצרנו סוכן סיווג פשוט, בואו נרחיב את יכולותיו על ידי חיבורו לעולם החיצוני באמצעות MCP.

כעת ניצור עוזר AI מלא שיכול:
*   לעבוד עם מערכת הקבצים (לקרוא, ליצור, לשנות קבצים)
*   לחפש מידע רלוונטי באינטרנט
*   לזכור את הקשר הדיאלוג
*   לטפל בשגיאות ולהתאושש מכשלים

#### מתיאוריה לכלים אמיתיים
זוכרים איך בתחילת המאמר דיברנו על כך ש**MCP הוא גשר בין רשת עצבית לסביבתה**? עכשיו תראו זאת בפועל. הסוכן שלנו יקבל גישה ל**כלים אמיתיים**:
```
# כלי מערכת קבצים
- read_file – קריאת קבצים
- write_file – כתיבה ויצירת קבצים
- list_directory – הצגת תוכן תיקיות
- create_directory – יצירת תיקיות

# כלי חיפוש אינטרנט
- brave_web_search – חיפוש באינטרנט
- get_web_content – קבלת תוכן דפים
```
זה כבר לא סוכן "צעצוע" – זהו **כלי עבודה** שיכול לפתור בעיות אמיתיות.

#### 📈 ארכיטקטורה: מפשוט למורכב

**1. תצורה כבסיס ליציבות**
```python
from dataclasses import dataclass

@dataclass
class AgentConfig:
    """תצורת סוכן AI פשוטה"""
    filesystem_path: str = "/path/to/work/directory"
    model_provider: ModelProvider = ModelProvider.OLLAMA
    use_memory: bool = True
    enable_web_search: bool = True

    def validate(self) -> None:
        """אימות תצורה"""
        if not os.path.exists(self.filesystem_path):
            raise ValueError(f"הנתיב אינו קיים: {self.filesystem_path}")
```
**למה זה חשוב?** בניגוד לדוגמת הסיווג, כאן הסוכן יוצר אינטראקציה עם מערכות חיצוניות. טעות אחת בנתיב הקובץ או מפתח API חסר – וכל הסוכן מפסיק לעבוד. **אימות בהפעלה** חוסך שעות של ניפוי באגים.

**2. מפעל מודלים: גמישות בחירה**
```python
def create_model(config: AgentConfig):
    """יוצר מודל בהתאם לתצורה"""
    provider = config.model_provider.value
    if provider == "ollama":
        return ChatOllama(model="qwen2.5:32b", base_url="http://localhost:11434")
    elif provider == "openai":
        return ChatOpenAI(model="gpt-4o-mini", api_key=os.getenv("OPENAI_API_KEY"))
    # ... ספקים אחרים
```
קוד אחד – מודלים רבים. רוצה מודל מקומי חינם? השתמש ב-Ollama. צריך דיוק מרבי? עבור ל-GPT-4. מהירות חשובה? נסה את DeepSeek. הקוד נשאר זהה.

**3. אינטגרציית MCP: חיבור לעולם האמיתי**
```python
async def _init_mcp_client(self):
    """אתחול לקוח MCP"""
    mcp_config = {
        "filesystem": {
            "command": "npx",
            "args": ["-y", "@modelcontextprotocol/server-filesystem", self.filesystem_path],
            "transport": "stdio"
        },
        "brave-search": {
            "command": "npx",
            "args": ["-y", "@modelcontextprotocol/server-brave-search@latest"],
            "transport": "stdio",
            "env": {"BRAVE_API_KEY": os.getenv("BRAVE_API_KEY")}
        }
    }
    self.mcp_client = MultiServerMCPClient(mcp_config)
    self.tools = await self.mcp_client.get_tools()
```
כאן מתרחשת העבודה המרכזית של MCP: אנו מחברים שרתי MCP חיצוניים לסוכן, המספקים סט כלים ופונקציות. הסוכן, בתורו, מקבל לא רק פונקציות בודדות, אלא הבנה הקשרית מלאה של אופן העבודה עם מערכת הקבצים והאינטרנט.

#### עמידות בפני שגיאות
בעולם האמיתי, הכל נשבר: הרשת אינה זמינה, קבצים נעולים, מפתחות API פג תוקף. הסוכן שלנו מוכן לכך:
```python
@retry_on_failure(max_retries=2, delay=1.0)
async def process_message(self, user_input: str, thread_id: str = "default") -> str:
    # ...
```
הדקורטור `@retry_on_failure` מנסה שוב אוטומטית פעולות במקרה של כשלים זמניים. המשתמש אפילו לא ישים לב שמשהו השתבש.

### סיכום: מתיאוריה לפרקטיקה של סוכני AI

היום עברנו דרך ארוכה ממושגים בסיסיים ועד ליצירת סוכני AI עובדים. בואו נסכם את מה שלמדנו והשגנו.

**מה שלמדנו**

**1. מושגי יסוד**
*   הבנו את ההבדל בין צ'אטבוטים לסוכני AI אמיתיים
*   הבנו את תפקידו של **MCP (Model Context Protocol)** כגשר בין המודל לעולם החיצון
*   למדנו את ארכיטקטורת **LangGraph** לבניית לוגיקת סוכן מורכבת

**2. מיומנויות מעשיות**
*   הגדרנו סביבת עבודה עם תמיכה במודלים בענן ומקומיים
*   יצרנו **סוכן מסווג** עם ארכיטקטורה אסינכרונית וניהול מצבים
*   בנינו **סוכן MCP** עם גישה למערכת הקבצים ולחיפוש אינטרנט

**3. דפוסי ארכיטקטורה**
*   שלטנו בתצורה מודולרית ובמפעלי מודלים
*   יישמנו טיפול בשגיאות ו**מנגנוני ניסיון חוזר** עבור פתרונות מוכנים לייצור

### יתרונות מפתח של הגישה
**LangGraph + MCP** נותנים לנו:
*   **שקיפות** – כל שלב של הסוכן מתועד וניתן למעקב
*   **הרחבה** – תכונות חדשות מתווספות באופן הצהרתי
*   **אמינות** – טיפול בשגיאות מובנה ושחזור
*   **גמישות** – תמיכה במודלים וספקים מרובים מהקופסה

### מסקנה

סוכני AI אינם מדע בדיוני עתידני, אלא **טכנולוגיה אמיתית של היום**. באמצעות LangGraph ו-MCP, אנו יכולים ליצור מערכות הפותרות בעיות עסקיות ספציפיות, הופכות שגרות לאוטומטיות ופותחות אפשרויות חדשות.

**העיקר – להתחיל.** קח את הקוד מהדוגמאות, התאם אותו למשימות שלך, התנסה. כל פרויקט הוא חוויה חדשה וצעד לקראת שליטה בתחום פיתוח AI.

בהצלחה בפרויקטים שלך!

---
*תגיות: python, ai, mcp, langchain, ai-assistant, ollama, ai-agents, local llm, langgraph, mcp-server*
*האבים: בלוג חברת Amvera, עיבוד שפה טבעית, בינה מלאכותית, Python, תכנות*
